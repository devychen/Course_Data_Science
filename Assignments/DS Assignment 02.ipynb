{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "814d3b69-2458-455d-93ba-dd5e220ad330",
   "metadata": {},
   "source": [
    "1.\n",
    "Create a new Jupyter notebook and import numpy. \n",
    "\n",
    "Load the contents of the second, fourth, and sixth column in Kuperman-BRM-data-2012.csv into a NumPy array, not forgetting to\n",
    "skip the header (you cannot work with mixed data yet). \n",
    "\n",
    "Each row now contains age-of-acquisition data for one English word. \n",
    "The first column will be the number of participants with known age of acquisition for the word, \n",
    "the second column the average age of acquistion,\n",
    "and the third column will be a frequency count in the SUBTLEX-US corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a97a313-d98a-4a2b-bccf-106ee38fe9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.900e+01 1.580e+00 4.120e+02]\n",
      " [1.900e+01 1.890e+00 5.289e+03]\n",
      " [2.100e+01 2.000e+00 5.000e-01]\n",
      " ...\n",
      " [2.100e+01       nan 5.000e-01]\n",
      " [2.100e+01       nan 5.000e-01]\n",
      " [2.100e+01       nan 5.000e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_path = '/Users/ychen/wise24homework/Kuperman-BRM-data-2012.csv'\n",
    "\n",
    "# Define the file name\n",
    "file_name = 'Kuperman-BRM-data-2012.csv'\n",
    "\n",
    "# read file, choose Column 2, 4, 6, skip the header\n",
    "data = np.genfromtxt(file_name, delimiter=',', skip_header=1, usecols=(1, 3, 5))\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "Normalize the last column in place in order to turn raw frequencies into percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化最后一列\n",
    "data[:, -1] = (data[:, -1] / data[:, -1].sum()) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算年龄小于等于5的单词数量\n",
    "words_acquired_in_first_five_years = np.sum(data[:, 1][data[:, 0] <= 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据习得年龄过滤数组\n",
    "filtered_data = data[data[:, 0] == 7]\n",
    "\n",
    "# 计算百分比\n",
    "percentage_tokens_understood = np.sum(filtered_data[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按最后一列排序，选择最后5000个词，过滤年龄小于等于10的单词\n",
    "top_5000_words = data[np.argsort(data[:, -1])[-5000:]]\n",
    "known_words_for_ten_year_old = np.sum(top_5000_words[:, 0][top_5000_words[:, 0] <= 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算百分比每年的增长\n",
    "percentage_growth_per_year = np.diff(data[:, -1])\n",
    "\n",
    "# 找到最大增长的年龄\n",
    "max_growth_age = np.argmax(percentage_growth_per_year) + 1  # +1 是因为索引从0开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每年的词汇量增长\n",
    "vocabulary_growth_per_year = [np.sum(data[:, 0][np.where((data[:, 0] == age) & (data[:, 0] > 1))]) for age in range(1, 18)]\n",
    "\n",
    "# 找到高峰年龄\n",
    "peak_growth_age = np.argmax(vocabulary_growth_per_year) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按最后一列排序，比较原始顺序和排序后的顺序，找到过早学习的单词数量\n",
    "sorted_indices = np.argsort(data[:, -1])\n",
    "premature_learning_count = np.sum(sorted_indices != np.arange(len(sorted_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算随机选择相同数量的单词的令牌覆盖率\n",
    "random_coverage_increase = np.sum(np.random.choice(data[:, 0], size=len(data)) / data[:, -1].sum()) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
