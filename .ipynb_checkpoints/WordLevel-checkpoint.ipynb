{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75126338-1de6-4556-aa2f-4eff2c627464",
   "metadata": {},
   "source": [
    "# 1. Preparation\n",
    "\n",
    "**1.0 Import Lexicons** <br>\n",
    "Initially we intended to use LIWC lexicon dictionairies (download [here](https://pypi.org/project/liwc/), and install using `!pip install -U liwc`). But it would require subscription which we could not afford. Therefore, we turned to a free equivalent called EMPATH whose guideline could be accessed [here](https://github.com/Ejhfast/empath-client). If it's still not working sufficiently, we will try the [SEANCE](https://www.linguisticanalysistools.org/seance.html). <br>\n",
    "\n",
    "**1.1 Explore EMPATHY, finding what existing lexicons from EMPATHY could be adopted directly.** <br>\n",
    "Then we explore the EMPATHY. In [Yarkoni (2011)](https://www.sciencedirect.com/science/article/pii/S0092656610000541), the referential article, the Table displays a correlation between LIWC lexicons and the five dimensions of Big-Five personalities. We use this table as a benchmark to filter the EMPATHY, find these that can be used, and apply them to our dataset. <br>\n",
    "\n",
    "**The results shows that:** <br>\n",
    "**EMPATHY has:** <br>\n",
    "affect, positive_emotions, negative_emotions, anger, sadness, hearing, communication, friends, family, swearing_terms <br>\n",
    "**Need Spacy for:** <br>\n",
    "pronouns(PRON), articles(DET), prepositions(PREP), numbers(NUM) <br>\n",
    "1st person sg/pl, 2nd person, 3rd person pronouns <br>\n",
    "Past/present/future tense vb. <br>\n",
    "**Neglect the rest:** <br>\n",
    "\n",
    "\n",
    "**1.2 Use Spacy to add lexicons that we need but missing from EMPATHY.** <br>\n",
    "For those missing, some of them such as 1st, 2nd, 3rd person pronouns could be added by using spacy to lemmatise, but for some of them there is a lack of instrument. We will take that as a limitation of this study. This new lexicon as a substitute of LIWC, we will call it EMPATHYe (Empathy extended).<br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0822a4dd-ab01-4254-8101-04dd13574065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched categories: ['money', 'domestic_work', 'sleep', 'occupation', 'family', 'leisure', 'school', 'social_media', 'blue_collar_job', 'optimism', 'home', 'superhero', 'religion', 'body', 'eating', 'sports', 'death', 'communication', 'hearing', 'weather', 'music', 'sound', 'work', 'sadness', 'emotional', 'affection', 'anger', 'white_collar_job', 'negative_emotion', 'friends', 'achievement', 'positive_emotion', 'musical']\n",
      "\n",
      "Not matched categories: ['total pronouns', 'pron', 'first person sing.', 'first person sing.', 'first person', 'secon person', 'third person', 'negation', 'assent', 'articles', 'prep', 'prepositions', 'number', 'affect', 'positive', 'negative', 'anxiety', 'cognitive', 'causation', 'insight', 'discrepancy', 'inhibition', 'tentative', 'certainty', 'sensory', 'seeing', 'feeling', 'social', 'references', 'friend', 'human', 'time', 'tense', 'space', 'up', 'down', 'inclusive', 'exclusive', 'motion', 'job', 'achieve', 'sport', 'tv', 'movie', 'finance', 'metaphysics', 'physical', 'sexuality', 'eat', 'drink']\n"
     ]
    }
   ],
   "source": [
    "### 1.0 Import Lexicon pkg ###\n",
    "!pip install empath spacy\n",
    "from empath import Empath\n",
    "lexicon = Empath()\n",
    "\n",
    "### 1.1 EXPLORING EMPATHY ###\n",
    "### WHAT EXISTING CLASSES IN EMPATHY COULD BE ADOPTED DIRECTLY ###\n",
    "# Print all category (class) names\n",
    "print(list(lexicon.cats.keys()))\n",
    "print()\n",
    "\n",
    "# Define the list of class (category) names we're looking for\n",
    "categories_to_check = [\"total pronouns\", \"pron\", \"first person sing.\", \"first person sing.\", \"first person\", \"secon person\", \"third person\",\n",
    " \"negation\", \"assent\", \"articles\", \"prep\", \"prepositions\", \"number\",\n",
    " \"affect\", \"positive\",\"optimism\", \"negative\", \"anxiety\", \"anger\", \"sadness\", \n",
    " \"cognitive\", \"causation\", \"insight\", \"discrepancy\", \"inhibition\", \"tentative\", \"certainty\", \n",
    " \"sensory\", \"seeing\", \"hearing\", \"feeling\", \"social\", \"communication\", \"references\",\n",
    " \"friend\", \"family\", \"human\", \"time\", \"tense\", \"space\", \"up\", \"down\", \n",
    " \"inclusive\", \"exclusive\", \"motion\", \"occupation\", \"school\", \"job\", \"work\", \"achieve\", \n",
    " \"leisure\", \"home\", \"sport\", \"tv\", \"movie\", \"music\", \"sound\", \"money\", \"finance\",\n",
    " \"metaphysics\", \"religion\", \"death\", \"physical\", \"body\", \"sexuality\", \"eat\", \"drink\", \"sleep\", \"groom\", \"swear\"] \n",
    "# Find matching categories (sub-string match, case insensitive)\n",
    "matched_categories = [cat for cat in lexicon.cats if any(search_term in cat.lower() for search_term in categories_to_check_lower)]\n",
    "not_matched_categories = [cat for cat in categories_to_check if not any(search_term in lexicon.cats for search_term in [cat.lower()])]\n",
    "# Output matched and not matched categories\n",
    "print(\"Matched categories:\", matched_categories)\n",
    "print()\n",
    "print(\"Not matched categories:\", not_matched_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00766a35-53ff-43a7-aaff-8ddc02242ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sexual': 0.2, 'love': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# do an example analysis for light testing\n",
    "result = lexicon.analyze(\"he kiss the other person\", normalize=True)\n",
    "filtered_result = {category: value for category, value in result.items() if value > 0}\n",
    "print(filtered_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f80c9c6-a2b8-48cc-a931-007a3a4a354c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1st person singular': ['I'], '1st person plural': ['we'], '2nd person': ['you'], '3rd person singular': ['he'], '3rd person plural': ['them']}\n"
     ]
    }
   ],
   "source": [
    "### 1.2 USE SPACY TO ADD MORE ### \n",
    "# [1] PERSONAL PRONOUNS\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") # load the English model\n",
    "# Defined a function to identify the personal pronouns in dataset\n",
    "def identify_personal_pronouns(text):\n",
    "    doc = nlp(text)\n",
    "    pronouns = {\n",
    "        \"1st person singular\": [],\n",
    "        \"1st person plural\": [],\n",
    "        \"2nd person\": [],\n",
    "        \"3rd person singular\": [],\n",
    "        \"3rd person plural\": []\n",
    "    }\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PRON\":  # only check pronouns\n",
    "            if token.text.lower() in [\"i\", \"me\", \"my\", \"mine\"]:  # 1st singular\n",
    "                pronouns[\"1st person singular\"].append(token.text)\n",
    "            elif token.text.lower() in [\"we\", \"us\", \"our\", \"ours\"]:  # 1st plural\n",
    "                pronouns[\"1st person plural\"].append(token.text)\n",
    "            elif token.text.lower() in [\"you\", \"your\", \"yours\"]:  # 2nd person\n",
    "                pronouns[\"2nd person\"].append(token.text)\n",
    "            elif token.text.lower() in [\"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"it\", \"its\"]:  # 3rd singular\n",
    "                pronouns[\"3rd person singular\"].append(token.text)\n",
    "            elif token.text.lower() in [\"they\", \"them\", \"their\", \"theirs\"]:  # 3rd plural\n",
    "                pronouns[\"3rd person plural\"].append(token.text)\n",
    "    \n",
    "    return pronouns\n",
    "\n",
    "# light testing with an example sentence\n",
    "text = \"I have a friend, and he said that we should meet you and them.\"\n",
    "result = identify_personal_pronouns(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7e60fe5-e490-4915-a189-e8ed18ec8918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'past': ['went'], 'present': ['go'], 'future': []}\n"
     ]
    }
   ],
   "source": [
    "# [2] VERB TENSE\n",
    "def identify_verb_tenses(text):\n",
    "    doc = nlp(text)\n",
    "    tenses = {\n",
    "        \"past\": [],\n",
    "        \"present\": [],\n",
    "        \"future\": []\n",
    "    }\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":  # verbs only\n",
    "            # 检查时态\n",
    "            if token.tag_ in [\"VBD\", \"VBN\"]:  # past\n",
    "                tenses[\"past\"].append(token.text)\n",
    "            elif token.tag_ in [\"VBZ\", \"VBP\", \"VB\"]:  # present\n",
    "                tenses[\"present\"].append(token.text)\n",
    "            elif token.text.lower().startswith(\"will\") or token.tag_ == \"MD\":  # future\n",
    "                tenses[\"future\"].append(token.text)    \n",
    "    return tenses\n",
    "\n",
    "# light testing\n",
    "text = \"I will go to the store tomorrow. He went there yesterday, and I am here now.\"\n",
    "result = identify_verb_tenses(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f462351e-9c66-4adf-bcd1-0463a442d51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', \"n't\"]\n"
     ]
    }
   ],
   "source": [
    "# [3] NEGATIONS\n",
    "def identify_negations(text):\n",
    "    doc = nlp(text)\n",
    "    negations = []  \n",
    "    for token in doc:\n",
    "        if token.dep_ == \"neg\": \n",
    "            negations.append(token.text)  \n",
    "    return negations\n",
    "# light testing\n",
    "text = \"I do not like apples, but I love oranges. He isn't coming to the party.\"\n",
    "result = identify_negations(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc01f706-de99-4624-82f9-8f5f34227d71",
   "metadata": {},
   "source": [
    "# 2. Data Processing\n",
    "\n",
    "**Recall the hypotheses for word level**\n",
    "\n",
    "We want to see if the correlations between LIWC categories and Big Five personlity traits align with the trend in Yarkoni(2011). That is: <br>\n",
    "|   EMPATHYe   | Neuroticism  | Extroversion |   Openness   |Agreeableness |Conscientiousness|\n",
    "|--------------|--------------|--------------|--------------|--------------|--------------|\n",
    "| pronouns     |      +       |      +       |       --     |       ++     |       -      |\n",
    "| 1st person sing.|   ++      |      +       |       -      |       +      |       0      |\n",
    "| 1st person plural|   -      |     ++       |       --     |       ++     |       +      |\n",
    "| 1st person   |++|+|--|++|+|\n",
    "| 2nd person   |--|++|--|+|0|\n",
    "| 3rd person   |+|+|-|+|-|\n",
    "| negations    |++|-|--|-|--|\n",
    "| articles     |--|-|++|+|++|\n",
    "| prepositions |-|-|++|+|+|\n",
    "| numbers      |-|--|--|++|+|\n",
    "| affect       |+|+|--|+|-|\n",
    "| positive emotions|-|++|--|++|+|\n",
    "| optimisim    |--|+|0|++|++|\n",
    "| negative emotions|++|+|0|--|--|\n",
    "| anger        |++|+|+|--|--|\n",
    "| sadness      |++|+|-|+|--|\n",
    "| hearing      |+|++|--|+|--|\n",
    "| communication|0|++|-|+|-|\n",
    "| friends      |--|++|-|++|+|\n",
    "| family       |-|+|--|++|+|\n",
    "| past tense vb.|+|-|--|+|0|\n",
    "| present tense vb.|+|-|--|0|-|\n",
    "| future tense vb.|-|-|-|-|-|\n",
    "| occupation   |+|--|+|-|+|\n",
    "| school       |+|-|+|-|-|\n",
    "| job/work     |+|--|+|-|+|\n",
    "| achievement  |+|--|-|+|--|\n",
    "| leisure      |-|++|--|++|+|\n",
    "| home         |0|+|--|++|+|\n",
    "| sports       |-|+|--|+|0|\n",
    "| music        |-|++|+|+|--|\n",
    "| money        |+|-|-|--|-|\n",
    "| religion     |-|++|+|+|-|\n",
    "| death        |+|+|++|--|--|\n",
    "| body states  |+|++|-|++|-|\n",
    "| sexuality    |+|++|0|++|-|\n",
    "| eating       |-|+|--|+|-|\n",
    "| sleep        |++|-|--|++|-|\n",
    "| swearing words|++|+|+|--|--|\n",
    "\n",
    "Our dataset use the collection of the complete 8 series of *Harry Potter* film series. Orginally we use only the first film but turns out it's not sufficient for a significant result, therefore we applied them all. <br>\n",
    "\n",
    "For word level, we follow the steps below: <br>\n",
    "\n",
    "**2.1 Build our own lexicon: *EMPATHYe*** <br>\n",
    "After the pre-processing stage, each character's lines form a separate dataset. Currently each dataset has the following labels: tokens, frequencies, postags. Now we need to add a new label called \"*empathye*\", which contains the needed lexicon information. Some could be proceeded directly by EMPATHY, some as stated before, need further processing using Spacy. <br>\n",
    "\n",
    "**2.2 Find the personality** <br> \n",
    "Based on the lexicons, we start the data analysis of a character's personalty.\n",
    "Step 1: count the frequencies per lexicon.\n",
    "Step 2: compare the lexicon frequencies between characters, using percentage = freq / number_of_tokens\n",
    "Step 3: verify the hypotheses, i.e. based on the percentage we would know if characters being more extroverted characters tend to use more certain words compare to those less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1185010f-074f-47d4-aa45-cff3c659f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.1 Build lexicons: EMPATHYe ###\n",
    "\n",
    "## 2.1.1 EMPATHY Parsing ##\n",
    "\n",
    "'''\n",
    "Matched categories: \n",
    "['money', 'domestic_work', 'sleep', 'occupation', \n",
    "'family', 'leisure', 'school', 'social_media', \n",
    "'blue_collar_job', 'optimism', 'home', \n",
    "'superhero', 'religion', 'body', 'eating', \n",
    "'sports', 'death', 'communication', 'hearing', \n",
    "'weather', 'music', 'sound', 'work', 'sadness', \n",
    "'emotional', 'affection', 'anger', \n",
    "'white_collar_job', 'negative_emotion', \n",
    "'friends', 'achievement', 'positive_emotion', 'musical']\n",
    "'''\n",
    "# rename \"musical\" to \"music\"\n",
    "\n",
    "# rename: combine \"blue_collar_job\" & \"white_collar_job\" & \"domestic_work\" & \"work\" to one category \"job\"\n",
    "\n",
    "## 2.1.2 Spacy Parsing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
