{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0822a4dd-ab01-4254-8101-04dd13574065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: empath in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.89)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from empath) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->empath) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->empath) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->empath) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->empath) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "###### 1.0 Install LIWC'S EQUIVALENT ######\n",
    "\n",
    "'''\n",
    "liwc pkg could be downloaded but it requires lexicon to use, which has to be purchsed.\n",
    "see: https://pypi.org/project/liwc/\n",
    "!pip install -U liwc\n",
    "\n",
    "alternatively we could use EMPATH\n",
    "Guideline here: https://github.com/Ejhfast/empath-client\n",
    "\n",
    "If still not working: \n",
    "Try out SEANCE. It's free, requires no programming experience, outperforms LIWC, and is open science\n",
    "https://www.linguisticanalysistools.org/seance.html\n",
    "'''\n",
    "\n",
    "!pip install empath spacy\n",
    "from empath import Empath\n",
    "lexicon = Empath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6912fa01-cba4-4759-9607-d05a8a728130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['help', 'office', 'dance', 'money', 'wedding', 'domestic_work', 'sleep', 'medical_emergency', 'cold', 'hate', 'cheerfulness', 'aggression', 'occupation', 'envy', 'anticipation', 'family', 'vacation', 'crime', 'attractive', 'masculine', 'prison', 'health', 'pride', 'dispute', 'nervousness', 'government', 'weakness', 'horror', 'swearing_terms', 'leisure', 'suffering', 'royalty', 'wealthy', 'tourism', 'furniture', 'school', 'magic', 'beach', 'journalism', 'morning', 'banking', 'social_media', 'exercise', 'night', 'kill', 'blue_collar_job', 'art', 'ridicule', 'play', 'computer', 'college', 'optimism', 'stealing', 'real_estate', 'home', 'divine', 'sexual', 'fear', 'irritability', 'superhero', 'business', 'driving', 'pet', 'childish', 'cooking', 'exasperation', 'religion', 'hipster', 'internet', 'surprise', 'reading', 'worship', 'leader', 'independence', 'movement', 'body', 'noise', 'eating', 'medieval', 'zest', 'confusion', 'water', 'sports', 'death', 'healing', 'legend', 'heroic', 'celebration', 'restaurant', 'violence', 'programming', 'dominant_heirarchical', 'military', 'neglect', 'swimming', 'exotic', 'love', 'hiking', 'communication', 'hearing', 'order', 'sympathy', 'hygiene', 'weather', 'anonymity', 'trust', 'ancient', 'deception', 'fabric', 'air_travel', 'fight', 'dominant_personality', 'music', 'vehicle', 'politeness', 'toy', 'farming', 'meeting', 'war', 'speaking', 'listen', 'urban', 'shopping', 'disgust', 'fire', 'tool', 'phone', 'gain', 'sound', 'injury', 'sailing', 'rage', 'science', 'work', 'appearance', 'valuable', 'warmth', 'youth', 'sadness', 'fun', 'emotional', 'joy', 'affection', 'traveling', 'fashion', 'ugliness', 'lust', 'shame', 'torment', 'economics', 'anger', 'politics', 'ship', 'clothing', 'car', 'strength', 'technology', 'breaking', 'shape_and_size', 'power', 'white_collar_job', 'animal', 'party', 'terrorism', 'smell', 'disappointment', 'poor', 'plant', 'pain', 'beauty', 'timidity', 'philosophy', 'negotiate', 'negative_emotion', 'cleaning', 'messaging', 'competing', 'law', 'friends', 'payment', 'achievement', 'alcohol', 'liquid', 'feminine', 'weapon', 'children', 'monster', 'ocean', 'giving', 'contentment', 'writing', 'rural', 'positive_emotion', 'musical']\n"
     ]
    }
   ],
   "source": [
    "###### EXPLORING EMPATHY ######\n",
    "\n",
    "# Print all category (class) names\n",
    "print(list(lexicon.cats.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45774b2e-67be-416c-9666-a2be6daea372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### WHAT EXISTING CLASSES IN EMPATHY COULD BE ADOPTED ######\n",
    "\n",
    "# Use Yarkoni (2011) Table 1 as the benchmark\n",
    "\n",
    "# Define the class (category) we're looking for\n",
    "class_name = \"SEE\"  \n",
    "# Find matching categories (sub-string match, case insensitive)\n",
    "matched_categories = [cat for cat in lexicon.cats if class_name.lower() in cat.lower()]\n",
    "# Check if any categories matched and print the results\n",
    "if matched_categories:\n",
    "    print(\"YES\")\n",
    "    print(\"Matched categories:\", matched_categories)\n",
    "else:\n",
    "    print(\"NO\")\n",
    "\n",
    "'''\n",
    "EMPATHY: \n",
    "affect, positive_emotions, negative_emotions, anger, sadness, hearing, communication, friends, family, swearing_terms\n",
    "\n",
    "SPACY:\n",
    "pronouns(PRON), articles(DET), prepositions(PREP), numbers(NUM)\n",
    "\n",
    "Maybe based on SPACY:\n",
    "1st person sg/pl, 2nd person, 3rd person pronouns\n",
    "Past/present/future tense vb.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35522c76-5aea-47cb-89f5-553eaab9324a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexicon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# do an example analysis\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mlexicon\u001b[49m\u001b[38;5;241m.\u001b[39manalyze(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkiss\u001b[39m\u001b[38;5;124m\"\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m filtered_result \u001b[38;5;241m=\u001b[39m {category: value \u001b[38;5;28;01mfor\u001b[39;00m category, value \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(filtered_result)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lexicon' is not defined"
     ]
    }
   ],
   "source": [
    "# do an example analysis\n",
    "result = lexicon.analyze(\"he kiss the other person\", normalize=True)\n",
    "filtered_result = {category: value for category, value in result.items() if value > 0}\n",
    "print(filtered_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f80c9c6-a2b8-48cc-a931-007a3a4a354c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1st person singular': ['I'], '1st person plural': ['we'], '2nd person': ['you'], '3rd person singular': ['he'], '3rd person plural': ['them']}\n"
     ]
    }
   ],
   "source": [
    "### PERSONAL PRONOUNS ###\n",
    "\n",
    "import spacy\n",
    "\n",
    "# 加载英语模型\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 定义一个函数来识别人称代词\n",
    "def identify_personal_pronouns(text):\n",
    "    doc = nlp(text)\n",
    "    pronouns = {\n",
    "        \"1st person singular\": [],\n",
    "        \"1st person plural\": [],\n",
    "        \"2nd person\": [],\n",
    "        \"3rd person singular\": [],\n",
    "        \"3rd person plural\": []\n",
    "    }\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PRON\":  # 仅检查代词\n",
    "            if token.text.lower() in [\"i\", \"me\", \"my\", \"mine\"]:  # 第一人称单数\n",
    "                pronouns[\"1st person singular\"].append(token.text)\n",
    "            elif token.text.lower() in [\"we\", \"us\", \"our\", \"ours\"]:  # 第一人称复数\n",
    "                pronouns[\"1st person plural\"].append(token.text)\n",
    "            elif token.text.lower() in [\"you\", \"your\", \"yours\"]:  # 第二人称\n",
    "                pronouns[\"2nd person\"].append(token.text)\n",
    "            elif token.text.lower() in [\"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"it\", \"its\"]:  # 第三人称单数\n",
    "                pronouns[\"3rd person singular\"].append(token.text)\n",
    "            elif token.text.lower() in [\"they\", \"them\", \"their\", \"theirs\"]:  # 第三人称复数\n",
    "                pronouns[\"3rd person plural\"].append(token.text)\n",
    "    \n",
    "    return pronouns\n",
    "\n",
    "# 示例句子\n",
    "text = \"I have a friend, and he said that we should meet you and them.\"\n",
    "result = identify_personal_pronouns(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7e60fe5-e490-4915-a189-e8ed18ec8918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'past': ['went'], 'present': ['go'], 'future': []}\n"
     ]
    }
   ],
   "source": [
    "### VERB TENSE ###\n",
    "\n",
    "# 定义一个函数来识别动词时态\n",
    "def identify_verb_tenses(text):\n",
    "    doc = nlp(text)\n",
    "    tenses = {\n",
    "        \"past\": [],\n",
    "        \"present\": [],\n",
    "        \"future\": []\n",
    "    }\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":  # 仅检查动词\n",
    "            # 检查时态\n",
    "            if token.tag_ in [\"VBD\", \"VBN\"]:  # 过去时或过去分词\n",
    "                tenses[\"past\"].append(token.text)\n",
    "            elif token.tag_ in [\"VBZ\", \"VBP\", \"VB\"]:  # 现在时\n",
    "                tenses[\"present\"].append(token.text)\n",
    "            elif token.text.lower().startswith(\"will\") or token.tag_ == \"MD\":  # 将来时\n",
    "                tenses[\"future\"].append(token.text)\n",
    "    \n",
    "    return tenses\n",
    "\n",
    "# 示例句子\n",
    "text = \"I will go to the store tomorrow. He went there yesterday, and I am here now.\"\n",
    "result = identify_verb_tenses(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f462351e-9c66-4adf-bcd1-0463a442d51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', \"n't\"]\n"
     ]
    }
   ],
   "source": [
    "### NEGATIONS ###\n",
    "# 定义一个函数来识别否定词\n",
    "def identify_negations(text):\n",
    "    doc = nlp(text)\n",
    "    negations = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.dep_ == \"neg\":  # 检查是否为否定词\n",
    "            negations.append(token.text)\n",
    "    \n",
    "    return negations\n",
    "\n",
    "# 示例句子\n",
    "text = \"I do not like apples, but I love oranges. He isn't coming to the party.\"\n",
    "result = identify_negations(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e01c21d-8d47-4aec-b5a5-a30d13a0939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Data processing ###\n",
    "\n",
    "# Database: lines per person\n",
    "# Put the sentences in, give each a lexicon marker, this will be a new category\n",
    "# Use previous studies' conclusion on characters' BIG-5, \n",
    "#   we explore if correlations between Big Five personality traits and LIWC categories\n",
    "#   align with conclusions from Yarkoni (2011) Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034ed3e-0023-4611-a096-36aa3bcbe1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Word / lexicon / character / Freq.\n",
    "\n",
    "character personality tendency\n",
    "\n",
    "coefficient\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
